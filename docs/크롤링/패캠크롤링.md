# 크롤러

> 조직적+자동화 방법으로 웹을 탐색하는 프로그램 from 위키백과

## 크롤러가 작동하는 방법

> Seeds : 탐색할 사이트를 정의

## 웹 크롤러 vs 웹 스크래퍼

1. 크롤러는 꽤나 어려운 기술
2. 대부분의 강의,글에서 설명하는것은 웹 스크래퍼

> 웹 스크레핑 : 웹사이트에서 정보를 자동 추출,수집하는 프로그램

## 아무 웹사이트나 크롤링하면 될까?

> 안된다. 크롤링할 사이트의 주소를 robots.txt를 찾아보자

### robots.txt?

> 크롤러가 해당 사이트의 데이터 수집을 허용할지 금지할지 알려주는 문서

> www.naver.com/robots.txt 로 확인할 수 있음

### 크롤리엥 사용되는 모듈

1. Axios + Cheerio
2. Selenium, beautifulsoup, scrapy
3. Puppeteer

### Axios + Cheerio

> HTTP 요청(Axios) + HTML DOM Parser 사용(Cheerio)

```
npm i axios
```

### Puppeteer

> delay 로딩 또는 브라우저 동작에 따라 처리할 수 있음

1. Node.js를 통해 크롬 브라우저를 실행
2. 사용자가 원하는 뷰포트, 네트워크 환경등을 설정 가능
3. 마우스,키보드, 터치 스크린 등을 코드를 통해 사람이 사용하는 것처럼 구현 가능
4. 타임라인 트레이싱, 스크린샷, PDF 다운로드, 확장프로그램 테스트, 작업 자동화 등 사용가능
5. SPA 크롤링, pre-redered content 생성 가능
