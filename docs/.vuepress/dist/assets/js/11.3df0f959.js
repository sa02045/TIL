(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{364:function(t,s,a){"use strict";a.r(s);var n=a(44),r=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"벨만포드-알고리즘"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#벨만포드-알고리즘"}},[t._v("#")]),t._v(" 벨만포드 알고리즘")]),t._v(" "),a("blockquote",[a("p",[t._v("다익스트라 알고리즘은 한 정점에서 모든 정점까지의 최단경로를 구하는 알고리즘이지만, 음수 간선을 하나라도 포함하는 경우 사용할 수 없습니다.")])]),t._v(" "),a("blockquote",[a("p",[t._v("벨만 포드 알고리즘은 음수간선이 있는 경우 해결할 수 있는 알고리즘 입니다.")])]),t._v(" "),a("ol",[a("li",[t._v("시작점에서 각 정점까지 가는 최단거리의 상한을 예측한뒤 예측 값과 실제 최단 거리사이의 오차를 반복적으로 줄여갑니다.")]),t._v(" "),a("li",[t._v("배열 upper[]에 각 정점까지의 최단 거리의 상한을 담습니다.")]),t._v(" "),a("li",[t._v("배열 값은 알고리즘이 진행됨에 따라 점점 줄어들게 디ㅗ고 알고리즘이 종료하게 되면 실제 최단거리를 담게 됩니다.")])]),t._v(" "),a("h2",{attrs:{id:"동작과정"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#동작과정"}},[t._v("#")]),t._v(" 동작과정")]),t._v(" "),a("ol",[a("li",[t._v("시작지점 s의 upper[s]=0으로 초기화하고 나머지 원소를 INF로 초기화 합니다")]),t._v(" "),a("li",[t._v("예측값을 실제 최단 거리에 가깝게 갱신하기 위해 최단거리 특성을 이용합니다")]),t._v(" "),a("li",[t._v("시작점 s에서 두 도착점 u,v까지의 최단거리 dist[u]와 dist[v]에 대해 다음 조건은 항상 참입니다.")])]),t._v(" "),a("blockquote",[a("p",[t._v("dist[v]<= dist[u]+w(u,v)\n시작점에서 v까지의 최단거리는 (시작점에서 u까지의 최단거리+ u와v의 최단거리) 보다 항상 작거나 같습니다")])]),t._v(" "),a("ol",{attrs:{start:"4"}},[a("li",[t._v("따라서 upper[v]를 upper[u] + w(u,v)로 줄일 수 있고 이 과정을 relax 완화한다고 표현합니다.")]),t._v(" "),a("li",[t._v("이러한 완화 과정을 모든 간선에 대해 반복적으로 실행하면, 실제 우리가 원하는 최단 거리에 가까워집니다.")])]),t._v(" "),a("h2",{attrs:{id:"종료조건과-정당성의-증명"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#종료조건과-정당성의-증명"}},[t._v("#")]),t._v(" 종료조건과 정당성의 증명")]),t._v(" "),a("ol",[a("li",[t._v("모든 간선에 대한 완화과정은 |v| -1 번이면 충분합니다.")])]),t._v(" "),a("h2",{attrs:{id:"음수사이클의-판정"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#음수사이클의-판정"}},[t._v("#")]),t._v(" 음수사이클의 판정")]),t._v(" "),a("ol",[a("li",[t._v("간단한 변형을 통해 벨만-포드 알고리즘이 음수 사이클의 존배여부를 판정할수 있습니다.")]),t._v(" "),a("li",[t._v("음수사이클의 존재여부를 판정하려먼 |v|-1번의 완화과정대신 |v|번의 완화만 시도하면 됩니다.")]),t._v(" "),a("li",[t._v("즉 |V|번의 완화로 성공이 된다면 음수사이클이 있다고 판정할 수 있습니다.")])]),t._v(" "),a("div",{staticClass:"language-cpp extra-class"},[a("pre",{pre:!0,attrs:{class:"language-cpp"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//정점개수 V")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" V"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nvector"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" pair"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" adj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("MAX_V"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//벨만포드의 한번동작으로 배열(vector)을 반환합니다.")]),t._v("\nvector"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("bellmanFord")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" src"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    vector"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("upper")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("V"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("INF"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    upper"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("src"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("bool")]),t._v(" updated"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// V번 반복")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" iter"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" iter"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("V"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        updated "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 하나의 정점에 대해 완화를 시도한다")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" here"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" here"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("V"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" i"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("adj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" there "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("second"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 완화가 가능하다면 완화한다")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// updated로 각 정점에서 완화가능하다는 표시를 함")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("upper"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("there"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" upper"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    upper"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("there"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" upper"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    updated"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 모든 간선에 대해 완화가 실패했을 경우 V-1을 돌 필요없이 종료한다.")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("updated"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// V번째 순회에서도 완화가 성공했다면 음수 사이클이 있음")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("updated"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" upper"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("clear")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" upper"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=r.exports}}]);